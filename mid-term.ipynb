{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-22T09:47:14.629865Z",
     "start_time": "2025-11-22T09:47:14.621892Z"
    }
   },
   "source": "text = \"My name is Umair Imran. I'm a Student at Univeristy of Central Punjab Lahore,Pakistan. My age is 21 years. My CGPA is 3.53. Allama Iqbal Airport is in Lahore. UCP Building is very modern and elegent.\"",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:43:20.229278Z",
     "start_time": "2025-11-22T09:43:20.225780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ],
   "id": "c7efc3b6c8c2df91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/umairimran/OLD DISK/Univeristy/7th Semester/Intro to NLP/nlp_lab/.venv/bin/python\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:43:43.329516Z",
     "start_time": "2025-11-22T09:43:24.233731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n"
   ],
   "id": "bc28ad22939c6cce",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/umairimran/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/umairimran/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/umairimran/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:47:20.181473Z",
     "start_time": "2025-11-22T09:47:20.171704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text=text.lower()\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)\n",
    "\n",
    "#remove puncation\n",
    "tokens = [t for t in tokens if t not in string.punctuation]\n",
    "\n",
    "# Stopwords removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [t for t in tokens if t not in stop_words]\n",
    "\n",
    "# Lemmatization\n",
    "lemm = WordNetLemmatizer()\n",
    "lem_tokens = [lemm.lemmatize(t) for t in tokens]\n",
    "\n",
    "print(\"Processed Tokens:\", lem_tokens)"
   ],
   "id": "86e05fe2c58c0cf2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'name', 'is', 'umair', 'imran', '.', 'i', \"'m\", 'a', 'student', 'at', 'univeristy', 'of', 'central', 'punjab', 'lahore', ',', 'pakistan', '.', 'my', 'age', 'is', '21', 'years', '.', 'my', 'cgpa', 'is', '3.53.', 'allama', 'iqbal', 'airport', 'is', 'in', 'lahore', '.', 'ucp', 'building', 'is', 'very', 'modern', 'and', 'elegent', '.']\n",
      "Processed Tokens: ['name', 'umair', 'imran', \"'m\", 'student', 'univeristy', 'central', 'punjab', 'lahore', 'pakistan', 'age', '21', 'year', 'cgpa', '3.53.', 'allama', 'iqbal', 'airport', 'lahore', 'ucp', 'building', 'modern', 'elegent']\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:47:37.068799Z",
     "start_time": "2025-11-22T09:47:37.063006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "fd = FreqDist(lem_tokens)\n",
    "print(fd.most_common())\n"
   ],
   "id": "a45d5986d7a543",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('lahore', 2), ('name', 1), ('umair', 1), ('imran', 1), (\"'m\", 1), ('student', 1), ('univeristy', 1), ('central', 1), ('punjab', 1), ('pakistan', 1), ('age', 1), ('21', 1), ('year', 1), ('cgpa', 1), ('3.53.', 1), ('allama', 1), ('iqbal', 1), ('airport', 1), ('ucp', 1), ('building', 1), ('modern', 1), ('elegent', 1)]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Simple Extractive Summarization\n",
   "id": "412ae5d8c2c58b25"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:48:50.434954Z",
     "start_time": "2025-11-22T09:48:50.422627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "# Score sentences by word frequency\n",
    "word_freq = FreqDist(word_tokenize(text.lower()))\n",
    "sentence_scores = {}\n",
    "\n",
    "for sent in sentences:\n",
    "    for word in word_tokenize(sent.lower()):\n",
    "        if word in word_freq:\n",
    "            sentence_scores[sent] = sentence_scores.get(sent, 0) + word_freq[word]\n",
    "\n",
    "summary = max(sentence_scores, key=sentence_scores.get)\n",
    "print(\"Summary:\", summary)\n"
   ],
   "id": "b707deaca21c0772",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: my cgpa is 3.53. allama iqbal airport is in lahore.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "NER",
   "id": "f8f6905abb4dc60e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T11:27:04.854882Z",
     "start_time": "2025-11-22T11:27:04.346120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text=\" \".join(lem_tokens)\n",
    "print(text)\n",
    "doc=nlp(text)\n",
    "\n",
    "\n",
    "displacy.render(doc,style=\"ent\")"
   ],
   "id": "9e91e87de54bb94b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name umair imran 'm student univeristy central punjab lahore pakistan age 21 year cgpa 3.53. allama iqbal airport lahore ucp building modern elegent\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">name umair imran 'm student univeristy central punjab lahore pakistan \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    age 21 year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " cgpa \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3.53\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    allama iqbal airport lahore ucp building modern\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " elegent</div></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T11:30:05.792689Z",
     "start_time": "2025-11-22T11:30:05.768183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "\n",
    "#POS\n",
    "\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,\" | \",token.pos_)\n"
   ],
   "id": "5ae8c0a9323abe77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The  |  DET\n",
      "quick  |  ADJ\n",
      "brown  |  ADJ\n",
      "fox  |  NOUN\n",
      "jumps  |  VERB\n",
      "over  |  ADP\n",
      "the  |  DET\n",
      "lazy  |  ADJ\n",
      "dog  |  NOUN\n",
      ".  |  PUNCT\n"
     ]
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_lab)",
   "language": "python",
   "name": "nlp_lab_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
